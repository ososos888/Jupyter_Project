{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR in Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR data 선언\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model ( nn.Sequential은 코드에 적힌 순서대로 값을 전달해 처리한다. linear -> sigmoid )\n",
    "model = torch.nn.Sequential(linear, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer / BInary Cross Entropy 사용(0, 1 이므로)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6975341439247131\n",
      "100 0.6931471824645996\n",
      "200 0.6931471824645996\n",
      "300 0.6931471824645996\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471824645996\n",
      "700 0.6931471824645996\n",
      "800 0.6931471824645996\n",
      "900 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "1100 0.6931471824645996\n",
      "1200 0.6931471824645996\n",
      "1300 0.6931471824645996\n",
      "1400 0.6931471824645996\n",
      "1500 0.6931471824645996\n",
      "1600 0.6931471824645996\n",
      "1700 0.6931471824645996\n",
      "1800 0.6931471824645996\n",
      "1900 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "2100 0.6931471824645996\n",
      "2200 0.6931471824645996\n",
      "2300 0.6931471824645996\n",
      "2400 0.6931471824645996\n",
      "2500 0.6931471824645996\n",
      "2600 0.6931471824645996\n",
      "2700 0.6931471824645996\n",
      "2800 0.6931471824645996\n",
      "2900 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "3100 0.6931471824645996\n",
      "3200 0.6931471824645996\n",
      "3300 0.6931471824645996\n",
      "3400 0.6931471824645996\n",
      "3500 0.6931471824645996\n",
      "3600 0.6931471824645996\n",
      "3700 0.6931471824645996\n",
      "3800 0.6931471824645996\n",
      "3900 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "4100 0.6931471824645996\n",
      "4200 0.6931471824645996\n",
      "4300 0.6931471824645996\n",
      "4400 0.6931471824645996\n",
      "4500 0.6931471824645996\n",
      "4600 0.6931471824645996\n",
      "4700 0.6931471824645996\n",
      "4800 0.6931471824645996\n",
      "4900 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "5100 0.6931471824645996\n",
      "5200 0.6931471824645996\n",
      "5300 0.6931471824645996\n",
      "5400 0.6931471824645996\n",
      "5500 0.6931471824645996\n",
      "5600 0.6931471824645996\n",
      "5700 0.6931471824645996\n",
      "5800 0.6931471824645996\n",
      "5900 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "6100 0.6931471824645996\n",
      "6200 0.6931471824645996\n",
      "6300 0.6931471824645996\n",
      "6400 0.6931471824645996\n",
      "6500 0.6931471824645996\n",
      "6600 0.6931471824645996\n",
      "6700 0.6931471824645996\n",
      "6800 0.6931471824645996\n",
      "6900 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "7100 0.6931471824645996\n",
      "7200 0.6931471824645996\n",
      "7300 0.6931471824645996\n",
      "7400 0.6931471824645996\n",
      "7500 0.6931471824645996\n",
      "7600 0.6931471824645996\n",
      "7700 0.6931471824645996\n",
      "7800 0.6931471824645996\n",
      "7900 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "8100 0.6931471824645996\n",
      "8200 0.6931471824645996\n",
      "8300 0.6931471824645996\n",
      "8400 0.6931471824645996\n",
      "8500 0.6931471824645996\n",
      "8600 0.6931471824645996\n",
      "8700 0.6931471824645996\n",
      "8800 0.6931471824645996\n",
      "8900 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "9100 0.6931471824645996\n",
      "9200 0.6931471824645996\n",
      "9300 0.6931471824645996\n",
      "9400 0.6931471824645996\n",
      "9500 0.6931471824645996\n",
      "9600 0.6931471824645996\n",
      "9700 0.6931471824645996\n",
      "9800 0.6931471824645996\n",
      "9900 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    \n",
    "    # cost/loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 200번 이후로 loss가 일정하며 학습이 제대로 되지 않을음 확인할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      " Correct:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      " Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', hypothesis.detach().cpu().numpy(), '\\n Correct: ', predicted.detach().cpu().numpy(), \n",
    "          '\\n Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단층 Perceptron으로는 제대로 구현이 불가능함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR In Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR data 선언\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layer\n",
    "w1 = torch.Tensor(2, 2)\n",
    "b1 = torch.Tensor(2)\n",
    "w2 = torch.Tensor(2, 1)\n",
    "b2 = torch.Tensor(1)\n",
    "\n",
    "learning_rate = 1\n",
    "# sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "#  derivative of the sigmoid function\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nan\n",
      "100 nan\n",
      "200 nan\n",
      "300 nan\n",
      "400 nan\n",
      "500 nan\n",
      "600 nan\n",
      "700 nan\n",
      "800 nan\n",
      "900 nan\n",
      "1000 nan\n",
      "1100 nan\n",
      "1200 nan\n",
      "1300 nan\n",
      "1400 nan\n",
      "1500 nan\n",
      "1600 nan\n",
      "1700 nan\n",
      "1800 nan\n",
      "1900 nan\n",
      "2000 nan\n",
      "2100 nan\n",
      "2200 nan\n",
      "2300 nan\n",
      "2400 nan\n",
      "2500 nan\n",
      "2600 nan\n",
      "2700 nan\n",
      "2800 nan\n",
      "2900 nan\n",
      "3000 nan\n",
      "3100 nan\n",
      "3200 nan\n",
      "3300 nan\n",
      "3400 nan\n",
      "3500 nan\n",
      "3600 nan\n",
      "3700 nan\n",
      "3800 nan\n",
      "3900 nan\n",
      "4000 nan\n",
      "4100 nan\n",
      "4200 nan\n",
      "4300 nan\n",
      "4400 nan\n",
      "4500 nan\n",
      "4600 nan\n",
      "4700 nan\n",
      "4800 nan\n",
      "4900 nan\n",
      "5000 nan\n",
      "5100 nan\n",
      "5200 nan\n",
      "5300 nan\n",
      "5400 nan\n",
      "5500 nan\n",
      "5600 nan\n",
      "5700 nan\n",
      "5800 nan\n",
      "5900 nan\n",
      "6000 nan\n",
      "6100 nan\n",
      "6200 nan\n",
      "6300 nan\n",
      "6400 nan\n",
      "6500 nan\n",
      "6600 nan\n",
      "6700 nan\n",
      "6800 nan\n",
      "6900 nan\n",
      "7000 nan\n",
      "7100 nan\n",
      "7200 nan\n",
      "7300 nan\n",
      "7400 nan\n",
      "7500 nan\n",
      "7600 nan\n",
      "7700 nan\n",
      "7800 nan\n",
      "7900 nan\n",
      "8000 nan\n",
      "8100 nan\n",
      "8200 nan\n",
      "8300 nan\n",
      "8400 nan\n",
      "8500 nan\n",
      "8600 nan\n",
      "8700 nan\n",
      "8800 nan\n",
      "8900 nan\n",
      "9000 nan\n",
      "9100 nan\n",
      "9200 nan\n",
      "9300 nan\n",
      "9400 nan\n",
      "9500 nan\n",
      "9600 nan\n",
      "9700 nan\n",
      "9800 nan\n",
      "9900 nan\n",
      "10000 nan\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    # Propergation -> Backpropergarion을 반복하며 진행한다.\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X, w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    # Binary Cross Entropy Loss\n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred))\n",
    "    \n",
    "    # Back prob\n",
    "    \n",
    "    # Loss derivative(BCE 미분식)\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2, 0, 1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_b1)\n",
    "    \n",
    "    # Weight update\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[0.00171033]\n",
      " [0.9977189 ]\n",
      " [0.9977095 ]\n",
      " [0.00153983]] \n",
      " Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      " Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', hypothesis.detach().cpu().numpy(), '\\n Correct: ', predicted.detach().cpu().numpy(), \n",
    "          '\\n Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code:xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR data 선언\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 Layer(2개)와 sigmoid 함수 선언\n",
    "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7035230398178101\n",
      "100 0.6934325098991394\n",
      "200 0.6932744979858398\n",
      "300 0.6932134628295898\n",
      "400 0.6931830644607544\n",
      "500 0.6931648254394531\n",
      "600 0.693152129650116\n",
      "700 0.6931419372558594\n",
      "800 0.6931324601173401\n",
      "900 0.693122386932373\n",
      "1000 0.6931099891662598\n",
      "1100 0.6930927634239197\n",
      "1200 0.6930667161941528\n",
      "1300 0.6930224299430847\n",
      "1400 0.6929371356964111\n",
      "1500 0.692742109298706\n",
      "1600 0.6921645998954773\n",
      "1700 0.6895726323127747\n",
      "1800 0.6702017188072205\n",
      "1900 0.5715908408164978\n",
      "2000 0.23000909388065338\n",
      "2100 0.0819261372089386\n",
      "2200 0.04671409726142883\n",
      "2300 0.032176896929740906\n",
      "2400 0.024387534707784653\n",
      "2500 0.019571945071220398\n",
      "2600 0.01631409488618374\n",
      "2700 0.013969474472105503\n",
      "2800 0.012204252183437347\n",
      "2900 0.010828915983438492\n",
      "3000 0.009728006087243557\n",
      "3100 0.008827459067106247\n",
      "3200 0.008077488280832767\n",
      "3300 0.007443435490131378\n",
      "3400 0.0069005852565169334\n",
      "3500 0.006430664099752903\n",
      "3600 0.006019984371960163\n",
      "3700 0.0056580533273518085\n",
      "3800 0.0053367409855127335\n",
      "3900 0.005049640312790871\n",
      "4000 0.004791527055203915\n",
      "4100 0.004558303859084845\n",
      "4200 0.004346525762230158\n",
      "4300 0.0041533359326422215\n",
      "4400 0.003976508043706417\n",
      "4500 0.003813954070210457\n",
      "4600 0.0036640369798988104\n",
      "4700 0.0035254338290542364\n",
      "4800 0.003396824700757861\n",
      "4900 0.0032771886326372623\n",
      "5000 0.003165625501424074\n",
      "5100 0.0030613995622843504\n",
      "5200 0.0029637168627232313\n",
      "5300 0.002871992066502571\n",
      "5400 0.0027858202811330557\n",
      "5500 0.0027046024333685637\n",
      "5600 0.002627948299050331\n",
      "5700 0.0025554834865033627\n",
      "5800 0.0024868790060281754\n",
      "5900 0.0024218792095780373\n",
      "6000 0.0023600952699780464\n",
      "6100 0.0023014224134385586\n",
      "6200 0.0022455905564129353\n",
      "6300 0.0021923310123384\n",
      "6400 0.0021415534429252148\n",
      "6500 0.002093078102916479\n",
      "6600 0.0020467108115553856\n",
      "6700 0.002002331428229809\n",
      "6800 0.0019598808139562607\n",
      "6900 0.001919133705087006\n",
      "7000 0.0018800159450620413\n",
      "7100 0.0018425120506435633\n",
      "7200 0.0018064278410747647\n",
      "7300 0.0017717333976179361\n",
      "7400 0.001738338847644627\n",
      "7500 0.0017061844700947404\n",
      "7600 0.0016751507064327598\n",
      "7700 0.0016452970448881388\n",
      "7800 0.0016163848340511322\n",
      "7900 0.0015885180328041315\n",
      "8000 0.0015615776646882296\n",
      "8100 0.001535578165203333\n",
      "8200 0.0015103555051609874\n",
      "8300 0.001485999091528356\n",
      "8400 0.0014624042669311166\n",
      "8500 0.0014395115431398153\n",
      "8600 0.0014173357049003243\n",
      "8700 0.0013958318158984184\n",
      "8800 0.0013749701902270317\n",
      "8900 0.0013547504786401987\n",
      "9000 0.0013350534718483686\n",
      "9100 0.0013159686932340264\n",
      "9200 0.0012973917182534933\n",
      "9300 0.0012793224304914474\n",
      "9400 0.0012617604807019234\n",
      "9500 0.0012446915498003364\n",
      "9600 0.001228055451065302\n",
      "9700 0.001211822498589754\n",
      "9800 0.001196082099340856\n",
      "9900 0.0011806702241301537\n",
      "10000 0.0011657212162390351\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
    "# define cost/Loss & optimozer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/Loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[1.1144429e-03]\n",
      " [9.9846280e-01]\n",
      " [9.9896157e-01]\n",
      " [9.6936122e-04]] \n",
      " Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      " Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', hypothesis.detach().cpu().numpy(), '\\n Correct: ', predicted.detach().cpu().numpy(), \n",
    "          '\\n Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code: xor-nn-wide-deep(4층)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR data 선언\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 Layer(4개)와 sigmoid 함수 선언\n",
    "linear1 = torch.nn.Linear(2, 10, bias=True)\n",
    "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
    "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7161834239959717\n",
      "100 0.6931208968162537\n",
      "200 0.6931166052818298\n",
      "300 0.6931120157241821\n",
      "400 0.693107008934021\n",
      "500 0.6931014657020569\n",
      "600 0.693095326423645\n",
      "700 0.6930884122848511\n",
      "800 0.6930806040763855\n",
      "900 0.693071722984314\n",
      "1000 0.6930615305900574\n",
      "1100 0.6930496692657471\n",
      "1200 0.6930357217788696\n",
      "1300 0.6930188536643982\n",
      "1400 0.6929985284805298\n",
      "1500 0.6929736137390137\n",
      "1600 0.6929424405097961\n",
      "1700 0.6929025053977966\n",
      "1800 0.6928502321243286\n",
      "1900 0.6927796602249146\n",
      "2000 0.6926810145378113\n",
      "2100 0.6925365328788757\n",
      "2200 0.6923128366470337\n",
      "2300 0.6919382810592651\n",
      "2400 0.6912395358085632\n",
      "2500 0.6897046566009521\n",
      "2600 0.6852677464485168\n",
      "2700 0.6636131405830383\n",
      "2800 0.4901348352432251\n",
      "2900 0.05120769143104553\n",
      "3000 0.011127297766506672\n",
      "3100 0.00567008089274168\n",
      "3200 0.0036980737932026386\n",
      "3300 0.002708381274715066\n",
      "3400 0.00212107808329165\n",
      "3500 0.0017350923735648394\n",
      "3600 0.0014633642276749015\n",
      "3700 0.0012623455841094255\n",
      "3800 0.0011079877149313688\n",
      "3900 0.0009859782876446843\n",
      "4000 0.0008872214239090681\n",
      "4100 0.000805744668468833\n",
      "4200 0.0007374873966909945\n",
      "4300 0.0006794792134314775\n",
      "4400 0.0006296157371252775\n",
      "4500 0.000586270703934133\n",
      "4600 0.000548324896954\n",
      "4700 0.0005148533382453024\n",
      "4800 0.00048505046288482845\n",
      "4900 0.0004584239795804024\n",
      "5000 0.00043440706213004887\n",
      "5100 0.0004127163556404412\n",
      "5200 0.0003930683888029307\n",
      "5300 0.00037509045796468854\n",
      "5400 0.0003586481907404959\n",
      "5500 0.0003435030812397599\n",
      "5600 0.00032958053634501994\n",
      "5700 0.00031670162570662796\n",
      "5800 0.00030476192478090525\n",
      "5900 0.00029362732311710715\n",
      "6000 0.0002832679310813546\n",
      "6100 0.00027359428349882364\n",
      "6200 0.0002645169442985207\n",
      "6300 0.0002560060820542276\n",
      "6400 0.0002480318653397262\n",
      "6500 0.00024050488718785346\n",
      "6600 0.00023341018822975457\n",
      "6700 0.00022668816382065415\n",
      "6800 0.0002203686162829399\n",
      "6900 0.00021436208044178784\n",
      "7000 0.00020865368423983455\n",
      "7100 0.0002032136108027771\n",
      "7200 0.00019808653451036662\n",
      "7300 0.0001931979786604643\n",
      "7400 0.00018850318156182766\n",
      "7500 0.0001840468612499535\n",
      "7600 0.0001797992445062846\n",
      "7700 0.00017574537196196616\n",
      "7800 0.0001718405692372471\n",
      "7900 0.000168084807228297\n",
      "8000 0.00016453771968372166\n",
      "8100 0.0001610800827620551\n",
      "8200 0.00015775658539496362\n",
      "8300 0.0001545970153529197\n",
      "8400 0.000151556683704257\n",
      "8500 0.00014859088696539402\n",
      "8600 0.00014578906120732427\n",
      "8700 0.00014301702321972698\n",
      "8800 0.0001404089416610077\n",
      "8900 0.00013786047929897904\n",
      "9000 0.0001354312407784164\n",
      "9100 0.00013303181913215667\n",
      "9200 0.00013075163587927818\n",
      "9300 0.0001285310572711751\n",
      "9400 0.00012639991473406553\n",
      "9500 0.00012434327800292522\n",
      "9600 0.00012231647269800305\n",
      "9700 0.00012036417319905013\n",
      "9800 0.00011850129521917552\n",
      "9900 0.00011665331840049475\n",
      "10000 0.00011485007416922599\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid)\n",
    "# define cost/Loss & optimozer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    # cost/Loss function\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[9.1147675e-05]\n",
      " [9.9988830e-01]\n",
      " [9.9989271e-01]\n",
      " [1.4922999e-04]] \n",
      " Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      " Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', hypothesis.detach().cpu().numpy(), '\\n Correct: ', predicted.detach().cpu().numpy(), \n",
    "          '\\n Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
