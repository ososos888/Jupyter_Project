{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimation (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting <br>\n",
    "epoch가 클수록 Train Loss가 감소한다.  \n",
    "validation set, validation loss\n",
    "validation loss가 증가하면 overfitting이 되고있다.<br><br>\n",
    "\n",
    "More data  \n",
    "Less features (data 분포의 특징을 적게 사용한다)  \n",
    "Regularization  \n",
    "  * Early Stopping  \n",
    "  * Reducing Network Size  \n",
    "  * Weight Decay  \n",
    "  * Dropout  \n",
    "  * Batch Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Approach to Train DNN\n",
    "\n",
    "1. Make a neural network architecture  \n",
    "2. Train and check that model is over-fitted  \n",
    "  * if it is not, increase the model size(deeper and wider).\n",
    "  * if it is, add regularization,, such as drop-out, batch-normalization.\n",
    "3. Repeat from step-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bbccc22c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 생성.( x = (m,3), y = (m,))\n",
    "x_train = torch.FloatTensor([[1, 2, 1],\n",
    "                             [1, 3, 2],\n",
    "                             [1, 3, 4],\n",
    "                             [1, 5, 5],\n",
    "                             [1, 7, 5],\n",
    "                             [1, 2, 5],\n",
    "                             [1, 6, 6],\n",
    "                             [1, 7, 7]\n",
    "                            ])\n",
    "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x test = (m', 3), y test(m', )\n",
    "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
    "y_test = torch.LongTensor([2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 선언\n",
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1개의 linear layer(3개의 elem -> 3개의 elem)\n",
    "        self.linear = nn.Linear(3, 3)\n",
    "    def forward(self, x):\n",
    "        # linear를 통과 (m,3) -> (m,3)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 함수 선언\n",
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "        \n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "        \n",
    "        # Cost 계산. cross entropy 사용(예측값과 y_train값)\n",
    "        cost = F.cross_entropy(prediction, y_train)\n",
    "        \n",
    "        # cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "        epoch+1, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 함수 선언\n",
    "def test(model, optimizer, x_test, y_test):\n",
    "    # model에 x_test를 통과시킨다.\n",
    "    prediction = model(x_test)\n",
    "    # max값을 뽑아낸다.\n",
    "    predicted_classes = prediction.max(1)[1]\n",
    "    correct_count = (predicted_classes == y_test).sum().item()\n",
    "    # 예측값과 결과값을 cross entropy를 구한다.\n",
    "    cost = F.cross_entropy(prediction, y_test)\n",
    "    \n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(\n",
    "    correct_count / len(y_test) * 100, cost.item()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 Cost: 2.939317\n",
      "Epoch    2/20 Cost: 1.887239\n",
      "Epoch    3/20 Cost: 1.055398\n",
      "Epoch    4/20 Cost: 0.936401\n",
      "Epoch    5/20 Cost: 0.917493\n",
      "Epoch    6/20 Cost: 0.911811\n",
      "Epoch    7/20 Cost: 0.906384\n",
      "Epoch    8/20 Cost: 0.901102\n",
      "Epoch    9/20 Cost: 0.895959\n",
      "Epoch   10/20 Cost: 0.890947\n",
      "Epoch   11/20 Cost: 0.886062\n",
      "Epoch   12/20 Cost: 0.881298\n",
      "Epoch   13/20 Cost: 0.876650\n",
      "Epoch   14/20 Cost: 0.872114\n",
      "Epoch   15/20 Cost: 0.867685\n",
      "Epoch   16/20 Cost: 0.863359\n",
      "Epoch   17/20 Cost: 0.859132\n",
      "Epoch   18/20 Cost: 0.855000\n",
      "Epoch   19/20 Cost: 0.850961\n",
      "Epoch   20/20 Cost: 0.847009\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0% Cost: 0.208701\n"
     ]
    }
   ],
   "source": [
    "test(model, optimizer, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 Cost: 1.609761\n",
      "Epoch    2/20 Cost: 1021978.125000\n",
      "Epoch    3/20 Cost: 1689950.875000\n",
      "Epoch    4/20 Cost: 1358893.250000\n",
      "Epoch    5/20 Cost: 1308616.500000\n",
      "Epoch    6/20 Cost: 922955.812500\n",
      "Epoch    7/20 Cost: 1207138.375000\n",
      "Epoch    8/20 Cost: 1430491.500000\n",
      "Epoch    9/20 Cost: 1612018.250000\n",
      "Epoch   10/20 Cost: 616429.062500\n",
      "Epoch   11/20 Cost: 1189680.000000\n",
      "Epoch   12/20 Cost: 1439951.000000\n",
      "Epoch   13/20 Cost: 707054.125000\n",
      "Epoch   14/20 Cost: 2022955.750000\n",
      "Epoch   15/20 Cost: 52230.765625\n",
      "Epoch   16/20 Cost: 792968.437500\n",
      "Epoch   17/20 Cost: 814951.000000\n",
      "Epoch   18/20 Cost: 1214866.625000\n",
      "Epoch   19/20 Cost: 1844830.750000\n",
      "Epoch   20/20 Cost: 428228.156250\n"
     ]
    }
   ],
   "source": [
    "# Learning rate가 너무 큰 경우 \n",
    "optimizer = optim.SGD(model.parameters(), lr=1e5)\n",
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1/20 Cost: 2.395043\n",
      "Epoch    2/20 Cost: 1.349992\n",
      "Epoch    3/20 Cost: 1.172284\n",
      "Epoch    4/20 Cost: 1.154202\n",
      "Epoch    5/20 Cost: 1.143523\n",
      "Epoch    6/20 Cost: 1.133134\n",
      "Epoch    7/20 Cost: 1.123014\n",
      "Epoch    8/20 Cost: 1.113150\n",
      "Epoch    9/20 Cost: 1.103535\n",
      "Epoch   10/20 Cost: 1.094160\n",
      "Epoch   11/20 Cost: 1.085017\n",
      "Epoch   12/20 Cost: 1.076100\n",
      "Epoch   13/20 Cost: 1.067403\n",
      "Epoch   14/20 Cost: 1.058919\n",
      "Epoch   15/20 Cost: 1.050642\n",
      "Epoch   16/20 Cost: 1.042568\n",
      "Epoch   17/20 Cost: 1.034689\n",
      "Epoch   18/20 Cost: 1.027001\n",
      "Epoch   19/20 Cost: 1.019498\n",
      "Epoch   20/20 Cost: 1.012176\n"
     ]
    }
   ],
   "source": [
    "# Learning rate가 너무 작은 경우\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "적절한 Learning rate의 값을 찾아야한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date의 zero-centor와 nomalize\n",
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674, -0.3758, -0.8398],\n",
      "        [ 0.7418,  0.2778,  0.5863],\n",
      "        [ 0.3799,  0.5229,  0.3486],\n",
      "        [ 1.0132,  1.0948,  1.1409],\n",
      "        [-1.0674, -1.5197, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "# Standardization(정규분포화, (N,0))를 통한 normalize\n",
    "mu = x_train.mean(dim=0)\n",
    "sigma = x_train.std(dim=0)\n",
    "norm_x_train = (x_train - mu) / sigma\n",
    "print(norm_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs):\n",
    "\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 개선\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost: 29719.886719\n",
      "Epoch    1/20 Cost: 18875.123047\n",
      "Epoch    2/20 Cost: 12037.903320\n",
      "Epoch    3/20 Cost: 7692.181152\n",
      "Epoch    4/20 Cost: 4919.672363\n",
      "Epoch    5/20 Cost: 3147.808350\n",
      "Epoch    6/20 Cost: 2014.549438\n",
      "Epoch    7/20 Cost: 1289.471191\n",
      "Epoch    8/20 Cost: 825.476379\n",
      "Epoch    9/20 Cost: 528.530640\n",
      "Epoch   10/20 Cost: 338.483002\n",
      "Epoch   11/20 Cost: 216.847198\n",
      "Epoch   12/20 Cost: 138.993744\n",
      "Epoch   13/20 Cost: 89.161400\n",
      "Epoch   14/20 Cost: 57.262451\n",
      "Epoch   15/20 Cost: 36.840950\n",
      "Epoch   16/20 Cost: 23.765465\n",
      "Epoch   17/20 Cost: 15.391520\n",
      "Epoch   18/20 Cost: 10.026782\n",
      "Epoch   19/20 Cost: 6.588136\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, norm_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost: nan\n",
      "Epoch    1/20 Cost: nan\n",
      "Epoch    2/20 Cost: nan\n",
      "Epoch    3/20 Cost: nan\n",
      "Epoch    4/20 Cost: nan\n",
      "Epoch    5/20 Cost: nan\n",
      "Epoch    6/20 Cost: nan\n",
      "Epoch    7/20 Cost: nan\n",
      "Epoch    8/20 Cost: nan\n",
      "Epoch    9/20 Cost: nan\n",
      "Epoch   10/20 Cost: nan\n",
      "Epoch   11/20 Cost: nan\n",
      "Epoch   12/20 Cost: nan\n",
      "Epoch   13/20 Cost: nan\n",
      "Epoch   14/20 Cost: nan\n",
      "Epoch   15/20 Cost: nan\n",
      "Epoch   16/20 Cost: nan\n",
      "Epoch   17/20 Cost: nan\n",
      "Epoch   18/20 Cost: nan\n",
      "Epoch   19/20 Cost: nan\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
