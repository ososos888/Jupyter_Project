{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./img/10_15_RESNET.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x) # 3x3 stride = 2\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out) # 3x3 stride = 1\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # output의 size가 다르면(stride의 값이 커질 경우) +연산이 불가능해 지므로 이를 맞춰줘야 한다.\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes) #conv1x1(64,64)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)#conv3x3(64,64)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion) #conv1x1(64,256)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x) # 1x1 stride = 1\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out) # 3x3 stride = stride \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out) # 1x1 stride = 1\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-a3a037bf7c76>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-a3a037bf7c76>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    self.layer1 = self._make_layer(block, 64, layers[0]'''3''')\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class ResNet(nn.Module):\n",
    "    # model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #resnet 50 \n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "        \n",
    "        # inputs = 3x224x224\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # output.shape = 64x112x112\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # inputs = 64x112x112\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # output = 64x56x56\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0]'''3''')\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1]'''4''', stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2]'''6''', stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3]'''3''', stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        \n",
    "        downsample = None\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion: \n",
    "            \n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride), #conv1x1(256, 512, 2)\n",
    "                nn.BatchNorm2d(planes * block.expansion), #batchnrom2d(512)\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        \n",
    "        self.inplanes = planes * block.expansion #self.inplanes = 128 * 4\n",
    "        \n",
    "        for _ in range(1, blocks): \n",
    "            layers.append(block(self.inplanes, planes)) # * 3\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet18(pretrained=False, **kwargs):\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs) #=> 2*(2+2+2+2) +1(conv1) +1(fc)  = 16 +2 =resnet 18\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #=> 3*(3+4+6+3) +(conv1) +1(fc) = 48 +2 = 50\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet152(pretrained=False, **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs) # 3*(3+8+36+3) +2 = 150+2 = resnet152    \n",
    "    return mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = resnet.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_tracker(value_plot, value, num):\n",
    "    '''num, loss_value, are Tensor'''\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win = value_plot,\n",
    "             update='append'\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device =='cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "[125.30691805 122.95039414 113.86538318]\n",
      "[62.99321928 62.08870764 66.70489964]\n",
      "[0.49139968 0.48215841 0.44653091]\n",
      "[0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "\n",
    "train_data_mean = trainset.data.mean( axis=(0,1,2) )\n",
    "train_data_std = trainset.data.std( axis=(0,1,2) )\n",
    "\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)\n",
    "\n",
    "train_data_mean = train_data_mean / 255\n",
    "train_data_std = train_data_std / 255\n",
    "\n",
    "print(train_data_mean)\n",
    "print(train_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "# GPU 성능 문제로 batch_size를 64로 변경\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
    "                                         shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models.resnet as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1x1=resnet.conv1x1\n",
    "Bottleneck = resnet.Bottleneck\n",
    "BasicBlock= resnet.BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 16\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x.shape =[1, 16, 32,32]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        #x.shape =[1, 128, 32,32]\n",
    "        x = self.layer2(x)\n",
    "        #x.shape =[1, 256, 32,32]\n",
    "        x = self.layer3(x)\n",
    "        #x.shape =[1, 512, 16,16]\n",
    "        x = self.layer4(x)\n",
    "        #x.shape =[1, 1024, 8,8]\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device) \n",
    "#1(conv1) + 9(layer1) + 12(layer2) + 18(layer3) + 9(layer4) +1(fc)= ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1216, -0.0359, -0.2566, -0.1189,  0.2453,  0.2085,  0.1865, -0.2792,\n",
      "          0.2216,  0.0592]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor(1,3,32,32).to(device)\n",
    "out = resnet50(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(),opts=dict(title='Accuracy', legend=['Acc'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % acc)\n",
    "    if save:\n",
    "        torch.save(net.state_dict(), \"./model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "[1,    30] loss: 2.267\n",
      "[1,    60] loss: 2.102\n",
      "[1,    90] loss: 1.957\n",
      "[1,   120] loss: 1.867\n",
      "[1,   150] loss: 1.879\n",
      "[1,   180] loss: 1.789\n",
      "[1,   210] loss: 1.751\n",
      "[1,   240] loss: 1.724\n",
      "[1,   270] loss: 1.696\n",
      "[1,   300] loss: 1.657\n",
      "[1,   330] loss: 1.640\n",
      "[1,   360] loss: 1.613\n",
      "[1,   390] loss: 1.518\n",
      "[1,   420] loss: 1.602\n",
      "[1,   450] loss: 1.528\n",
      "[1,   480] loss: 1.500\n",
      "[1,   510] loss: 1.491\n",
      "[1,   540] loss: 1.435\n",
      "[1,   570] loss: 1.334\n",
      "[1,   600] loss: 1.413\n",
      "[1,   630] loss: 1.339\n",
      "[1,   660] loss: 1.348\n",
      "[1,   690] loss: 1.345\n",
      "[1,   720] loss: 1.376\n",
      "[1,   750] loss: 1.273\n",
      "[1,   780] loss: 1.264\n",
      "Accuracy of the network on the 10000 test images: 46 %\n",
      "[2,    30] loss: 1.203\n",
      "[2,    60] loss: 1.235\n",
      "[2,    90] loss: 1.208\n",
      "[2,   120] loss: 1.197\n",
      "[2,   150] loss: 1.178\n",
      "[2,   180] loss: 1.211\n",
      "[2,   210] loss: 1.210\n",
      "[2,   240] loss: 1.202\n",
      "[2,   270] loss: 1.102\n",
      "[2,   300] loss: 1.197\n",
      "[2,   330] loss: 1.157\n",
      "[2,   360] loss: 1.131\n",
      "[2,   390] loss: 1.129\n",
      "[2,   420] loss: 1.082\n",
      "[2,   450] loss: 1.108\n",
      "[2,   480] loss: 1.152\n",
      "[2,   510] loss: 1.092\n",
      "[2,   540] loss: 1.027\n",
      "[2,   570] loss: 1.074\n",
      "[2,   600] loss: 1.066\n",
      "[2,   630] loss: 1.041\n",
      "[2,   660] loss: 1.056\n",
      "[2,   690] loss: 1.067\n",
      "[2,   720] loss: 1.071\n",
      "[2,   750] loss: 1.051\n",
      "[2,   780] loss: 1.056\n",
      "Accuracy of the network on the 10000 test images: 58 %\n",
      "[3,    30] loss: 1.012\n",
      "[3,    60] loss: 1.019\n",
      "[3,    90] loss: 1.003\n",
      "[3,   120] loss: 1.020\n",
      "[3,   150] loss: 1.005\n",
      "[3,   180] loss: 1.029\n",
      "[3,   210] loss: 0.998\n",
      "[3,   240] loss: 1.018\n",
      "[3,   270] loss: 0.975\n",
      "[3,   300] loss: 1.001\n",
      "[3,   330] loss: 0.987\n",
      "[3,   360] loss: 1.033\n",
      "[3,   390] loss: 0.949\n",
      "[3,   420] loss: 0.936\n",
      "[3,   450] loss: 0.986\n",
      "[3,   480] loss: 0.951\n",
      "[3,   510] loss: 0.966\n",
      "[3,   540] loss: 0.950\n",
      "[3,   570] loss: 1.002\n",
      "[3,   600] loss: 0.942\n",
      "[3,   630] loss: 0.982\n",
      "[3,   660] loss: 1.012\n",
      "[3,   690] loss: 0.964\n",
      "[3,   720] loss: 0.970\n",
      "[3,   750] loss: 0.985\n",
      "[3,   780] loss: 0.961\n",
      "Accuracy of the network on the 10000 test images: 61 %\n",
      "[4,    30] loss: 0.972\n",
      "[4,    60] loss: 0.915\n",
      "[4,    90] loss: 0.934\n",
      "[4,   120] loss: 0.870\n",
      "[4,   150] loss: 0.945\n",
      "[4,   180] loss: 0.932\n",
      "[4,   210] loss: 0.896\n",
      "[4,   240] loss: 0.905\n",
      "[4,   270] loss: 0.956\n",
      "[4,   300] loss: 0.869\n",
      "[4,   330] loss: 0.884\n",
      "[4,   360] loss: 0.938\n",
      "[4,   390] loss: 0.928\n",
      "[4,   420] loss: 0.872\n",
      "[4,   450] loss: 0.907\n",
      "[4,   480] loss: 0.869\n",
      "[4,   510] loss: 0.877\n",
      "[4,   540] loss: 0.910\n",
      "[4,   570] loss: 0.868\n",
      "[4,   600] loss: 0.879\n",
      "[4,   630] loss: 0.855\n",
      "[4,   660] loss: 0.865\n",
      "[4,   690] loss: 0.909\n",
      "[4,   720] loss: 0.861\n",
      "[4,   750] loss: 0.840\n",
      "[4,   780] loss: 0.879\n",
      "Accuracy of the network on the 10000 test images: 64 %\n",
      "[5,    30] loss: 0.899\n",
      "[5,    60] loss: 0.829\n",
      "[5,    90] loss: 0.862\n",
      "[5,   120] loss: 0.812\n",
      "[5,   150] loss: 0.850\n",
      "[5,   180] loss: 0.810\n",
      "[5,   210] loss: 0.819\n",
      "[5,   240] loss: 0.841\n",
      "[5,   270] loss: 0.828\n",
      "[5,   300] loss: 0.795\n",
      "[5,   330] loss: 0.788\n",
      "[5,   360] loss: 0.863\n",
      "[5,   390] loss: 0.748\n",
      "[5,   420] loss: 0.855\n",
      "[5,   450] loss: 0.865\n",
      "[5,   480] loss: 0.801\n",
      "[5,   510] loss: 0.765\n",
      "[5,   540] loss: 0.837\n",
      "[5,   570] loss: 0.836\n",
      "[5,   600] loss: 0.792\n",
      "[5,   630] loss: 0.814\n",
      "[5,   660] loss: 0.766\n",
      "[5,   690] loss: 0.793\n",
      "[5,   720] loss: 0.830\n",
      "[5,   750] loss: 0.788\n",
      "[5,   780] loss: 0.797\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "[6,    30] loss: 0.796\n",
      "[6,    60] loss: 0.754\n",
      "[6,    90] loss: 0.831\n",
      "[6,   120] loss: 0.763\n",
      "[6,   150] loss: 0.773\n",
      "[6,   180] loss: 0.815\n",
      "[6,   210] loss: 0.754\n",
      "[6,   240] loss: 0.763\n",
      "[6,   270] loss: 0.791\n",
      "[6,   300] loss: 0.823\n",
      "[6,   330] loss: 0.752\n",
      "[6,   360] loss: 0.750\n",
      "[6,   390] loss: 0.772\n",
      "[6,   420] loss: 0.803\n",
      "[6,   450] loss: 0.746\n",
      "[6,   480] loss: 0.769\n",
      "[6,   510] loss: 0.727\n",
      "[6,   540] loss: 0.775\n",
      "[6,   570] loss: 0.813\n",
      "[6,   600] loss: 0.726\n",
      "[6,   630] loss: 0.751\n",
      "[6,   660] loss: 0.748\n",
      "[6,   690] loss: 0.736\n",
      "[6,   720] loss: 0.775\n",
      "[6,   750] loss: 0.751\n",
      "[6,   780] loss: 0.769\n",
      "Accuracy of the network on the 10000 test images: 67 %\n",
      "[7,    30] loss: 0.766\n",
      "[7,    60] loss: 0.717\n",
      "[7,    90] loss: 0.789\n",
      "[7,   120] loss: 0.665\n",
      "[7,   150] loss: 0.769\n",
      "[7,   180] loss: 0.722\n",
      "[7,   210] loss: 0.712\n",
      "[7,   240] loss: 0.783\n",
      "[7,   270] loss: 0.710\n",
      "[7,   300] loss: 0.736\n",
      "[7,   330] loss: 0.697\n",
      "[7,   360] loss: 0.764\n",
      "[7,   390] loss: 0.721\n",
      "[7,   420] loss: 0.701\n",
      "[7,   450] loss: 0.725\n",
      "[7,   480] loss: 0.716\n",
      "[7,   510] loss: 0.755\n",
      "[7,   540] loss: 0.782\n",
      "[7,   570] loss: 0.751\n",
      "[7,   600] loss: 0.728\n",
      "[7,   630] loss: 0.694\n",
      "[7,   660] loss: 0.719\n",
      "[7,   690] loss: 0.764\n",
      "[7,   720] loss: 0.763\n",
      "[7,   750] loss: 0.773\n",
      "[7,   780] loss: 0.773\n",
      "Accuracy of the network on the 10000 test images: 72 %\n",
      "[8,    30] loss: 0.618\n",
      "[8,    60] loss: 0.737\n",
      "[8,    90] loss: 0.716\n",
      "[8,   120] loss: 0.748\n",
      "[8,   150] loss: 0.717\n",
      "[8,   180] loss: 0.705\n",
      "[8,   210] loss: 0.739\n",
      "[8,   240] loss: 0.674\n",
      "[8,   270] loss: 0.703\n",
      "[8,   300] loss: 0.686\n",
      "[8,   330] loss: 0.767\n",
      "[8,   360] loss: 0.704\n",
      "[8,   390] loss: 0.730\n",
      "[8,   420] loss: 0.658\n",
      "[8,   450] loss: 0.674\n",
      "[8,   480] loss: 0.729\n",
      "[8,   510] loss: 0.703\n",
      "[8,   540] loss: 0.737\n",
      "[8,   570] loss: 0.656\n",
      "[8,   600] loss: 0.714\n",
      "[8,   630] loss: 0.735\n",
      "[8,   660] loss: 0.745\n",
      "[8,   690] loss: 0.691\n",
      "[8,   720] loss: 0.716\n",
      "[8,   750] loss: 0.753\n",
      "[8,   780] loss: 0.732\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[9,    30] loss: 0.696\n",
      "[9,    60] loss: 0.746\n",
      "[9,    90] loss: 0.650\n",
      "[9,   120] loss: 0.671\n",
      "[9,   150] loss: 0.700\n",
      "[9,   180] loss: 0.662\n",
      "[9,   210] loss: 0.756\n",
      "[9,   240] loss: 0.700\n",
      "[9,   270] loss: 0.723\n",
      "[9,   300] loss: 0.709\n",
      "[9,   330] loss: 0.709\n",
      "[9,   360] loss: 0.655\n",
      "[9,   390] loss: 0.657\n",
      "[9,   420] loss: 0.706\n",
      "[9,   450] loss: 0.656\n",
      "[9,   480] loss: 0.668\n",
      "[9,   510] loss: 0.697\n",
      "[9,   540] loss: 0.668\n",
      "[9,   570] loss: 0.687\n",
      "[9,   600] loss: 0.699\n",
      "[9,   630] loss: 0.700\n",
      "[9,   660] loss: 0.720\n",
      "[9,   690] loss: 0.675\n",
      "[9,   720] loss: 0.702\n",
      "[9,   750] loss: 0.697\n",
      "[9,   780] loss: 0.717\n",
      "Accuracy of the network on the 10000 test images: 71 %\n",
      "[10,    30] loss: 0.597\n",
      "[10,    60] loss: 0.538\n",
      "[10,    90] loss: 0.532\n",
      "[10,   120] loss: 0.552\n",
      "[10,   150] loss: 0.513\n",
      "[10,   180] loss: 0.541\n",
      "[10,   210] loss: 0.532\n",
      "[10,   240] loss: 0.490\n",
      "[10,   270] loss: 0.590\n",
      "[10,   300] loss: 0.553\n",
      "[10,   330] loss: 0.537\n",
      "[10,   360] loss: 0.564\n",
      "[10,   390] loss: 0.550\n",
      "[10,   420] loss: 0.521\n",
      "[10,   450] loss: 0.555\n",
      "[10,   480] loss: 0.535\n",
      "[10,   510] loss: 0.540\n",
      "[10,   540] loss: 0.512\n",
      "[10,   570] loss: 0.492\n",
      "[10,   600] loss: 0.581\n",
      "[10,   630] loss: 0.532\n",
      "[10,   660] loss: 0.558\n",
      "[10,   690] loss: 0.550\n",
      "[10,   720] loss: 0.522\n",
      "[10,   750] loss: 0.550\n",
      "[10,   780] loss: 0.529\n",
      "Accuracy of the network on the 10000 test images: 75 %\n",
      "[11,    30] loss: 0.558\n",
      "[11,    60] loss: 0.504\n",
      "[11,    90] loss: 0.531\n",
      "[11,   120] loss: 0.521\n",
      "[11,   150] loss: 0.533\n",
      "[11,   180] loss: 0.487\n",
      "[11,   210] loss: 0.533\n",
      "[11,   240] loss: 0.491\n",
      "[11,   270] loss: 0.502\n",
      "[11,   300] loss: 0.533\n",
      "[11,   330] loss: 0.529\n",
      "[11,   360] loss: 0.556\n",
      "[11,   390] loss: 0.528\n",
      "[11,   420] loss: 0.510\n",
      "[11,   450] loss: 0.517\n",
      "[11,   480] loss: 0.513\n",
      "[11,   510] loss: 0.530\n",
      "[11,   540] loss: 0.541\n",
      "[11,   570] loss: 0.500\n",
      "[11,   600] loss: 0.513\n",
      "[11,   630] loss: 0.481\n",
      "[11,   660] loss: 0.522\n",
      "[11,   690] loss: 0.543\n",
      "[11,   720] loss: 0.532\n",
      "[11,   750] loss: 0.540\n",
      "[11,   780] loss: 0.558\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[12,    30] loss: 0.529\n",
      "[12,    60] loss: 0.537\n",
      "[12,    90] loss: 0.546\n",
      "[12,   120] loss: 0.524\n",
      "[12,   150] loss: 0.489\n",
      "[12,   180] loss: 0.514\n",
      "[12,   210] loss: 0.542\n",
      "[12,   240] loss: 0.535\n",
      "[12,   270] loss: 0.475\n",
      "[12,   300] loss: 0.571\n",
      "[12,   330] loss: 0.548\n",
      "[12,   360] loss: 0.516\n",
      "[12,   390] loss: 0.537\n",
      "[12,   420] loss: 0.509\n",
      "[12,   450] loss: 0.521\n",
      "[12,   480] loss: 0.531\n",
      "[12,   510] loss: 0.522\n",
      "[12,   540] loss: 0.532\n",
      "[12,   570] loss: 0.535\n",
      "[12,   600] loss: 0.533\n",
      "[12,   630] loss: 0.523\n",
      "[12,   660] loss: 0.519\n",
      "[12,   690] loss: 0.493\n",
      "[12,   720] loss: 0.526\n",
      "[12,   750] loss: 0.531\n",
      "[12,   780] loss: 0.496\n",
      "Accuracy of the network on the 10000 test images: 74 %\n",
      "[13,    30] loss: 0.558\n",
      "[13,    60] loss: 0.521\n",
      "[13,    90] loss: 0.531\n",
      "[13,   120] loss: 0.501\n",
      "[13,   150] loss: 0.521\n",
      "[13,   180] loss: 0.519\n",
      "[13,   210] loss: 0.531\n",
      "[13,   240] loss: 0.496\n",
      "[13,   270] loss: 0.515\n",
      "[13,   300] loss: 0.507\n",
      "[13,   330] loss: 0.490\n",
      "[13,   360] loss: 0.518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,   390] loss: 0.539\n",
      "[13,   420] loss: 0.511\n",
      "[13,   450] loss: 0.536\n",
      "[13,   480] loss: 0.494\n",
      "[13,   510] loss: 0.523\n",
      "[13,   540] loss: 0.520\n",
      "[13,   570] loss: 0.533\n",
      "[13,   600] loss: 0.534\n",
      "[13,   630] loss: 0.572\n",
      "[13,   660] loss: 0.550\n",
      "[13,   690] loss: 0.500\n",
      "[13,   720] loss: 0.520\n",
      "[13,   750] loss: 0.512\n",
      "[13,   780] loss: 0.572\n",
      "Accuracy of the network on the 10000 test images: 76 %\n",
      "[14,    30] loss: 0.493\n",
      "[14,    60] loss: 0.512\n",
      "[14,    90] loss: 0.462\n",
      "[14,   120] loss: 0.493\n",
      "[14,   150] loss: 0.517\n",
      "[14,   180] loss: 0.492\n",
      "[14,   210] loss: 0.502\n",
      "[14,   240] loss: 0.501\n",
      "[14,   270] loss: 0.522\n",
      "[14,   300] loss: 0.488\n",
      "[14,   330] loss: 0.518\n",
      "[14,   360] loss: 0.563\n",
      "[14,   390] loss: 0.536\n",
      "[14,   420] loss: 0.494\n",
      "[14,   450] loss: 0.494\n",
      "[14,   480] loss: 0.530\n",
      "[14,   510] loss: 0.528\n",
      "[14,   540] loss: 0.518\n",
      "[14,   570] loss: 0.504\n",
      "[14,   600] loss: 0.521\n",
      "[14,   630] loss: 0.497\n",
      "[14,   660] loss: 0.539\n",
      "[14,   690] loss: 0.472\n",
      "[14,   720] loss: 0.496\n",
      "[14,   750] loss: 0.513\n",
      "[14,   780] loss: 0.525\n",
      "Accuracy of the network on the 10000 test images: 76 %\n",
      "[15,    30] loss: 0.500\n",
      "[15,    60] loss: 0.509\n",
      "[15,    90] loss: 0.486\n",
      "[15,   120] loss: 0.504\n",
      "[15,   150] loss: 0.462\n",
      "[15,   180] loss: 0.544\n",
      "[15,   210] loss: 0.540\n",
      "[15,   240] loss: 0.496\n",
      "[15,   270] loss: 0.467\n",
      "[15,   300] loss: 0.446\n",
      "[15,   330] loss: 0.492\n",
      "[15,   360] loss: 0.501\n",
      "[15,   390] loss: 0.491\n",
      "[15,   420] loss: 0.500\n",
      "[15,   450] loss: 0.502\n",
      "[15,   480] loss: 0.499\n",
      "[15,   510] loss: 0.494\n",
      "[15,   540] loss: 0.502\n",
      "[15,   570] loss: 0.489\n",
      "[15,   600] loss: 0.485\n",
      "[15,   630] loss: 0.536\n",
      "[15,   660] loss: 0.548\n",
      "[15,   690] loss: 0.536\n",
      "[15,   720] loss: 0.561\n",
      "[15,   750] loss: 0.459\n",
      "[15,   780] loss: 0.471\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[16,    30] loss: 0.463\n",
      "[16,    60] loss: 0.502\n",
      "[16,    90] loss: 0.481\n",
      "[16,   120] loss: 0.501\n",
      "[16,   150] loss: 0.546\n",
      "[16,   180] loss: 0.476\n",
      "[16,   210] loss: 0.534\n",
      "[16,   240] loss: 0.528\n",
      "[16,   270] loss: 0.496\n",
      "[16,   300] loss: 0.491\n",
      "[16,   330] loss: 0.534\n",
      "[16,   360] loss: 0.454\n",
      "[16,   390] loss: 0.495\n",
      "[16,   420] loss: 0.508\n",
      "[16,   450] loss: 0.479\n",
      "[16,   480] loss: 0.519\n",
      "[16,   510] loss: 0.519\n",
      "[16,   540] loss: 0.502\n",
      "[16,   570] loss: 0.491\n",
      "[16,   600] loss: 0.508\n",
      "[16,   630] loss: 0.514\n",
      "[16,   660] loss: 0.505\n",
      "[16,   690] loss: 0.485\n",
      "[16,   720] loss: 0.533\n",
      "[16,   750] loss: 0.500\n",
      "[16,   780] loss: 0.508\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[17,    30] loss: 0.490\n",
      "[17,    60] loss: 0.452\n",
      "[17,    90] loss: 0.471\n",
      "[17,   120] loss: 0.506\n",
      "[17,   150] loss: 0.494\n",
      "[17,   180] loss: 0.448\n",
      "[17,   210] loss: 0.465\n",
      "[17,   240] loss: 0.502\n",
      "[17,   270] loss: 0.471\n",
      "[17,   300] loss: 0.461\n",
      "[17,   330] loss: 0.463\n",
      "[17,   360] loss: 0.527\n",
      "[17,   390] loss: 0.474\n",
      "[17,   420] loss: 0.497\n",
      "[17,   450] loss: 0.516\n",
      "[17,   480] loss: 0.514\n",
      "[17,   510] loss: 0.512\n",
      "[17,   540] loss: 0.524\n",
      "[17,   570] loss: 0.461\n",
      "[17,   600] loss: 0.458\n",
      "[17,   630] loss: 0.457\n",
      "[17,   660] loss: 0.553\n",
      "[17,   690] loss: 0.509\n",
      "[17,   720] loss: 0.487\n",
      "[17,   750] loss: 0.482\n",
      "[17,   780] loss: 0.490\n",
      "Accuracy of the network on the 10000 test images: 79 %\n",
      "[18,    30] loss: 0.491\n",
      "[18,    60] loss: 0.485\n",
      "[18,    90] loss: 0.490\n",
      "[18,   120] loss: 0.478\n",
      "[18,   150] loss: 0.485\n",
      "[18,   180] loss: 0.463\n",
      "[18,   210] loss: 0.533\n",
      "[18,   240] loss: 0.492\n",
      "[18,   270] loss: 0.493\n",
      "[18,   300] loss: 0.474\n",
      "[18,   330] loss: 0.477\n",
      "[18,   360] loss: 0.517\n",
      "[18,   390] loss: 0.486\n",
      "[18,   420] loss: 0.520\n",
      "[18,   450] loss: 0.461\n",
      "[18,   480] loss: 0.498\n",
      "[18,   510] loss: 0.469\n",
      "[18,   540] loss: 0.434\n",
      "[18,   570] loss: 0.485\n",
      "[18,   600] loss: 0.499\n",
      "[18,   630] loss: 0.480\n",
      "[18,   660] loss: 0.476\n",
      "[18,   690] loss: 0.480\n",
      "[18,   720] loss: 0.459\n",
      "[18,   750] loss: 0.483\n",
      "[18,   780] loss: 0.480\n",
      "Accuracy of the network on the 10000 test images: 77 %\n",
      "[19,    30] loss: 0.509\n",
      "[19,    60] loss: 0.468\n",
      "[19,    90] loss: 0.497\n",
      "[19,   120] loss: 0.496\n",
      "[19,   150] loss: 0.476\n",
      "[19,   180] loss: 0.481\n",
      "[19,   210] loss: 0.476\n",
      "[19,   240] loss: 0.476\n",
      "[19,   270] loss: 0.468\n",
      "[19,   300] loss: 0.491\n",
      "[19,   330] loss: 0.493\n",
      "[19,   360] loss: 0.549\n",
      "[19,   390] loss: 0.439\n",
      "[19,   420] loss: 0.472\n",
      "[19,   450] loss: 0.456\n",
      "[19,   480] loss: 0.452\n",
      "[19,   510] loss: 0.470\n",
      "[19,   540] loss: 0.471\n",
      "[19,   570] loss: 0.477\n",
      "[19,   600] loss: 0.468\n",
      "[19,   630] loss: 0.492\n",
      "[19,   660] loss: 0.506\n",
      "[19,   690] loss: 0.445\n",
      "[19,   720] loss: 0.441\n",
      "[19,   750] loss: 0.487\n",
      "[19,   780] loss: 0.505\n",
      "Accuracy of the network on the 10000 test images: 78 %\n",
      "[20,    30] loss: 0.413\n",
      "[20,    60] loss: 0.340\n",
      "[20,    90] loss: 0.368\n",
      "[20,   120] loss: 0.345\n",
      "[20,   150] loss: 0.319\n",
      "[20,   180] loss: 0.330\n",
      "[20,   210] loss: 0.333\n",
      "[20,   240] loss: 0.353\n",
      "[20,   270] loss: 0.356\n",
      "[20,   300] loss: 0.372\n",
      "[20,   330] loss: 0.352\n",
      "[20,   360] loss: 0.347\n",
      "[20,   390] loss: 0.354\n",
      "[20,   420] loss: 0.341\n",
      "[20,   450] loss: 0.380\n",
      "[20,   480] loss: 0.348\n",
      "[20,   510] loss: 0.339\n",
      "[20,   540] loss: 0.349\n",
      "[20,   570] loss: 0.338\n",
      "[20,   600] loss: 0.330\n",
      "[20,   630] loss: 0.331\n",
      "[20,   660] loss: 0.381\n",
      "[20,   690] loss: 0.361\n",
      "[20,   720] loss: 0.355\n",
      "[20,   750] loss: 0.360\n",
      "[20,   780] loss: 0.373\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "[21,    30] loss: 0.326\n",
      "[21,    60] loss: 0.293\n",
      "[21,    90] loss: 0.295\n",
      "[21,   120] loss: 0.320\n",
      "[21,   150] loss: 0.329\n",
      "[21,   180] loss: 0.312\n",
      "[21,   210] loss: 0.345\n",
      "[21,   240] loss: 0.355\n",
      "[21,   270] loss: 0.333\n",
      "[21,   300] loss: 0.361\n",
      "[21,   330] loss: 0.317\n",
      "[21,   360] loss: 0.323\n",
      "[21,   390] loss: 0.331\n",
      "[21,   420] loss: 0.345\n",
      "[21,   450] loss: 0.341\n",
      "[21,   480] loss: 0.348\n",
      "[21,   510] loss: 0.387\n",
      "[21,   540] loss: 0.342\n",
      "[21,   570] loss: 0.364\n",
      "[21,   600] loss: 0.359\n",
      "[21,   630] loss: 0.317\n",
      "[21,   660] loss: 0.384\n",
      "[21,   690] loss: 0.361\n",
      "[21,   720] loss: 0.344\n",
      "[21,   750] loss: 0.364\n",
      "[21,   780] loss: 0.346\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "[22,    30] loss: 0.328\n",
      "[22,    60] loss: 0.332\n",
      "[22,    90] loss: 0.305\n",
      "[22,   120] loss: 0.315\n",
      "[22,   150] loss: 0.303\n",
      "[22,   180] loss: 0.336\n",
      "[22,   210] loss: 0.321\n",
      "[22,   240] loss: 0.322\n",
      "[22,   270] loss: 0.349\n",
      "[22,   300] loss: 0.317\n",
      "[22,   330] loss: 0.329\n",
      "[22,   360] loss: 0.325\n",
      "[22,   390] loss: 0.352\n",
      "[22,   420] loss: 0.343\n",
      "[22,   450] loss: 0.323\n",
      "[22,   480] loss: 0.312\n",
      "[22,   510] loss: 0.369\n",
      "[22,   540] loss: 0.374\n",
      "[22,   570] loss: 0.358\n",
      "[22,   600] loss: 0.362\n",
      "[22,   630] loss: 0.363\n",
      "[22,   660] loss: 0.352\n",
      "[22,   690] loss: 0.385\n",
      "[22,   720] loss: 0.370\n",
      "[22,   750] loss: 0.350\n",
      "[22,   780] loss: 0.349\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "[23,    30] loss: 0.341\n",
      "[23,    60] loss: 0.320\n",
      "[23,    90] loss: 0.327\n",
      "[23,   120] loss: 0.306\n",
      "[23,   150] loss: 0.293\n",
      "[23,   180] loss: 0.334\n",
      "[23,   210] loss: 0.332\n",
      "[23,   240] loss: 0.374\n",
      "[23,   270] loss: 0.315\n",
      "[23,   300] loss: 0.326\n",
      "[23,   330] loss: 0.336\n",
      "[23,   360] loss: 0.315\n",
      "[23,   390] loss: 0.316\n",
      "[23,   420] loss: 0.322\n",
      "[23,   450] loss: 0.323\n",
      "[23,   480] loss: 0.318\n",
      "[23,   510] loss: 0.361\n",
      "[23,   540] loss: 0.361\n",
      "[23,   570] loss: 0.345\n",
      "[23,   600] loss: 0.352\n",
      "[23,   630] loss: 0.357\n",
      "[23,   660] loss: 0.374\n",
      "[23,   690] loss: 0.362\n",
      "[23,   720] loss: 0.363\n",
      "[23,   750] loss: 0.327\n",
      "[23,   780] loss: 0.355\n",
      "Accuracy of the network on the 10000 test images: 80 %\n",
      "[24,    30] loss: 0.336\n",
      "[24,    60] loss: 0.284\n",
      "[24,    90] loss: 0.317\n",
      "[24,   120] loss: 0.312\n",
      "[24,   150] loss: 0.352\n",
      "[24,   180] loss: 0.302\n",
      "[24,   210] loss: 0.364\n",
      "[24,   240] loss: 0.323\n",
      "[24,   270] loss: 0.320\n",
      "[24,   300] loss: 0.316\n",
      "[24,   330] loss: 0.344\n",
      "[24,   360] loss: 0.332\n",
      "[24,   390] loss: 0.354\n",
      "[24,   420] loss: 0.326\n",
      "[24,   450] loss: 0.298\n",
      "[24,   480] loss: 0.306\n",
      "[24,   510] loss: 0.323\n",
      "[24,   540] loss: 0.368\n",
      "[24,   570] loss: 0.359\n",
      "[24,   600] loss: 0.363\n",
      "[24,   630] loss: 0.347\n",
      "[24,   660] loss: 0.355\n",
      "[24,   690] loss: 0.351\n",
      "[24,   720] loss: 0.340\n",
      "[24,   750] loss: 0.363\n",
      "[24,   780] loss: 0.371\n",
      "Accuracy of the network on the 10000 test images: 80 %\n",
      "[25,    30] loss: 0.343\n",
      "[25,    60] loss: 0.330\n",
      "[25,    90] loss: 0.295\n",
      "[25,   120] loss: 0.317\n",
      "[25,   150] loss: 0.343\n",
      "[25,   180] loss: 0.334\n",
      "[25,   210] loss: 0.339\n",
      "[25,   240] loss: 0.327\n",
      "[25,   270] loss: 0.310\n",
      "[25,   300] loss: 0.338\n",
      "[25,   330] loss: 0.342\n",
      "[25,   360] loss: 0.368\n",
      "[25,   390] loss: 0.356\n",
      "[25,   420] loss: 0.333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25,   450] loss: 0.293\n",
      "[25,   480] loss: 0.318\n",
      "[25,   510] loss: 0.334\n",
      "[25,   540] loss: 0.373\n",
      "[25,   570] loss: 0.373\n",
      "[25,   600] loss: 0.338\n",
      "[25,   630] loss: 0.344\n",
      "[25,   660] loss: 0.308\n",
      "[25,   690] loss: 0.312\n",
      "[25,   720] loss: 0.309\n",
      "[25,   750] loss: 0.315\n",
      "[25,   780] loss: 0.363\n",
      "Accuracy of the network on the 10000 test images: 80 %\n",
      "[26,    30] loss: 0.330\n",
      "[26,    60] loss: 0.330\n",
      "[26,    90] loss: 0.351\n",
      "[26,   120] loss: 0.296\n",
      "[26,   150] loss: 0.286\n",
      "[26,   180] loss: 0.312\n",
      "[26,   210] loss: 0.325\n",
      "[26,   240] loss: 0.349\n",
      "[26,   270] loss: 0.339\n",
      "[26,   300] loss: 0.358\n",
      "[26,   330] loss: 0.346\n",
      "[26,   360] loss: 0.326\n",
      "[26,   390] loss: 0.298\n",
      "[26,   420] loss: 0.327\n",
      "[26,   450] loss: 0.330\n",
      "[26,   480] loss: 0.322\n",
      "[26,   510] loss: 0.381\n",
      "[26,   540] loss: 0.317\n",
      "[26,   570] loss: 0.352\n",
      "[26,   600] loss: 0.335\n",
      "[26,   630] loss: 0.310\n",
      "[26,   660] loss: 0.335\n",
      "[26,   690] loss: 0.351\n",
      "[26,   720] loss: 0.333\n",
      "[26,   750] loss: 0.350\n",
      "[26,   780] loss: 0.366\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "[27,    30] loss: 0.356\n",
      "[27,    60] loss: 0.325\n",
      "[27,    90] loss: 0.328\n",
      "[27,   120] loss: 0.360\n",
      "[27,   150] loss: 0.306\n",
      "[27,   180] loss: 0.299\n",
      "[27,   210] loss: 0.327\n",
      "[27,   240] loss: 0.322\n",
      "[27,   270] loss: 0.328\n",
      "[27,   300] loss: 0.340\n",
      "[27,   330] loss: 0.326\n",
      "[27,   360] loss: 0.330\n",
      "[27,   390] loss: 0.323\n",
      "[27,   420] loss: 0.351\n",
      "[27,   450] loss: 0.329\n",
      "[27,   480] loss: 0.328\n",
      "[27,   510] loss: 0.327\n",
      "[27,   540] loss: 0.347\n",
      "[27,   570] loss: 0.331\n",
      "[27,   600] loss: 0.377\n",
      "[27,   630] loss: 0.343\n",
      "[27,   660] loss: 0.338\n",
      "[27,   690] loss: 0.319\n",
      "[27,   720] loss: 0.335\n",
      "[27,   750] loss: 0.333\n",
      "[27,   780] loss: 0.352\n",
      "Accuracy of the network on the 10000 test images: 82 %\n",
      "[28,    30] loss: 0.285\n",
      "[28,    60] loss: 0.308\n",
      "[28,    90] loss: 0.316\n",
      "[28,   120] loss: 0.302\n",
      "[28,   150] loss: 0.343\n",
      "[28,   180] loss: 0.329\n",
      "[28,   210] loss: 0.318\n",
      "[28,   240] loss: 0.323\n",
      "[28,   270] loss: 0.323\n",
      "[28,   300] loss: 0.317\n",
      "[28,   330] loss: 0.328\n",
      "[28,   360] loss: 0.358\n",
      "[28,   390] loss: 0.355\n",
      "[28,   420] loss: 0.335\n",
      "[28,   450] loss: 0.326\n",
      "[28,   480] loss: 0.341\n",
      "[28,   510] loss: 0.308\n",
      "[28,   540] loss: 0.314\n",
      "[28,   570] loss: 0.302\n",
      "[28,   600] loss: 0.327\n",
      "[28,   630] loss: 0.338\n",
      "[28,   660] loss: 0.352\n",
      "[28,   690] loss: 0.344\n",
      "[28,   720] loss: 0.326\n",
      "[28,   750] loss: 0.356\n",
      "[28,   780] loss: 0.360\n",
      "Accuracy of the network on the 10000 test images: 81 %\n",
      "[29,    30] loss: 0.304\n",
      "[29,    60] loss: 0.314\n",
      "[29,    90] loss: 0.321\n",
      "[29,   120] loss: 0.335\n",
      "[29,   150] loss: 0.313\n",
      "[29,   180] loss: 0.326\n",
      "[29,   210] loss: 0.280\n",
      "[29,   240] loss: 0.323\n",
      "[29,   270] loss: 0.319\n",
      "[29,   300] loss: 0.314\n",
      "[29,   330] loss: 0.316\n",
      "[29,   360] loss: 0.331\n",
      "[29,   390] loss: 0.315\n",
      "[29,   420] loss: 0.316\n",
      "[29,   450] loss: 0.310\n",
      "[29,   480] loss: 0.355\n",
      "[29,   510] loss: 0.345\n",
      "[29,   540] loss: 0.334\n",
      "[29,   570] loss: 0.359\n",
      "[29,   600] loss: 0.313\n",
      "[29,   630] loss: 0.305\n",
      "[29,   660] loss: 0.299\n",
      "[29,   690] loss: 0.343\n",
      "[29,   720] loss: 0.371\n",
      "[29,   750] loss: 0.346\n",
      "[29,   780] loss: 0.340\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "[30,    30] loss: 0.270\n",
      "[30,    60] loss: 0.268\n",
      "[30,    90] loss: 0.226\n",
      "[30,   120] loss: 0.244\n",
      "[30,   150] loss: 0.201\n",
      "[30,   180] loss: 0.198\n",
      "[30,   210] loss: 0.254\n",
      "[30,   240] loss: 0.219\n",
      "[30,   270] loss: 0.210\n",
      "[30,   300] loss: 0.212\n",
      "[30,   330] loss: 0.194\n",
      "[30,   360] loss: 0.201\n",
      "[30,   390] loss: 0.213\n",
      "[30,   420] loss: 0.219\n",
      "[30,   450] loss: 0.196\n",
      "[30,   480] loss: 0.227\n",
      "[30,   510] loss: 0.231\n",
      "[30,   540] loss: 0.225\n",
      "[30,   570] loss: 0.192\n",
      "[30,   600] loss: 0.192\n",
      "[30,   630] loss: 0.220\n",
      "[30,   660] loss: 0.214\n",
      "[30,   690] loss: 0.220\n",
      "[30,   720] loss: 0.216\n",
      "[30,   750] loss: 0.206\n",
      "[30,   780] loss: 0.217\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "[31,    30] loss: 0.176\n",
      "[31,    60] loss: 0.189\n",
      "[31,    90] loss: 0.186\n",
      "[31,   120] loss: 0.183\n",
      "[31,   150] loss: 0.173\n",
      "[31,   180] loss: 0.169\n",
      "[31,   210] loss: 0.181\n",
      "[31,   240] loss: 0.163\n",
      "[31,   270] loss: 0.210\n",
      "[31,   300] loss: 0.208\n",
      "[31,   330] loss: 0.213\n",
      "[31,   360] loss: 0.203\n",
      "[31,   390] loss: 0.214\n",
      "[31,   420] loss: 0.213\n",
      "[31,   450] loss: 0.230\n",
      "[31,   480] loss: 0.217\n",
      "[31,   510] loss: 0.228\n",
      "[31,   540] loss: 0.206\n",
      "[31,   570] loss: 0.218\n",
      "[31,   600] loss: 0.195\n",
      "[31,   630] loss: 0.200\n",
      "[31,   660] loss: 0.214\n",
      "[31,   690] loss: 0.193\n",
      "[31,   720] loss: 0.219\n",
      "[31,   750] loss: 0.191\n",
      "[31,   780] loss: 0.204\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "[32,    30] loss: 0.178\n",
      "[32,    60] loss: 0.166\n",
      "[32,    90] loss: 0.186\n",
      "[32,   120] loss: 0.180\n",
      "[32,   150] loss: 0.202\n",
      "[32,   180] loss: 0.181\n",
      "[32,   210] loss: 0.183\n",
      "[32,   240] loss: 0.202\n",
      "[32,   270] loss: 0.175\n",
      "[32,   300] loss: 0.171\n",
      "[32,   330] loss: 0.207\n",
      "[32,   360] loss: 0.211\n",
      "[32,   390] loss: 0.197\n",
      "[32,   420] loss: 0.157\n",
      "[32,   450] loss: 0.219\n",
      "[32,   480] loss: 0.231\n",
      "[32,   510] loss: 0.208\n",
      "[32,   540] loss: 0.193\n",
      "[32,   570] loss: 0.212\n",
      "[32,   600] loss: 0.169\n",
      "[32,   630] loss: 0.220\n",
      "[32,   660] loss: 0.242\n",
      "[32,   690] loss: 0.200\n",
      "[32,   720] loss: 0.205\n",
      "[32,   750] loss: 0.197\n",
      "[32,   780] loss: 0.212\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[33,    30] loss: 0.187\n",
      "[33,    60] loss: 0.165\n",
      "[33,    90] loss: 0.182\n",
      "[33,   120] loss: 0.160\n",
      "[33,   150] loss: 0.169\n",
      "[33,   180] loss: 0.181\n",
      "[33,   210] loss: 0.184\n",
      "[33,   240] loss: 0.201\n",
      "[33,   270] loss: 0.203\n",
      "[33,   300] loss: 0.199\n",
      "[33,   330] loss: 0.185\n",
      "[33,   360] loss: 0.174\n",
      "[33,   390] loss: 0.185\n",
      "[33,   420] loss: 0.197\n",
      "[33,   450] loss: 0.204\n",
      "[33,   480] loss: 0.212\n",
      "[33,   510] loss: 0.208\n",
      "[33,   540] loss: 0.185\n",
      "[33,   570] loss: 0.226\n",
      "[33,   600] loss: 0.211\n",
      "[33,   630] loss: 0.204\n",
      "[33,   660] loss: 0.237\n",
      "[33,   690] loss: 0.194\n",
      "[33,   720] loss: 0.177\n",
      "[33,   750] loss: 0.220\n",
      "[33,   780] loss: 0.218\n",
      "Accuracy of the network on the 10000 test images: 85 %\n",
      "[34,    30] loss: 0.160\n",
      "[34,    60] loss: 0.170\n",
      "[34,    90] loss: 0.183\n",
      "[34,   120] loss: 0.187\n",
      "[34,   150] loss: 0.187\n",
      "[34,   180] loss: 0.159\n",
      "[34,   210] loss: 0.161\n",
      "[34,   240] loss: 0.183\n",
      "[34,   270] loss: 0.181\n",
      "[34,   300] loss: 0.204\n",
      "[34,   330] loss: 0.201\n",
      "[34,   360] loss: 0.223\n",
      "[34,   390] loss: 0.203\n",
      "[34,   420] loss: 0.191\n",
      "[34,   450] loss: 0.236\n",
      "[34,   480] loss: 0.193\n",
      "[34,   510] loss: 0.199\n",
      "[34,   540] loss: 0.187\n",
      "[34,   570] loss: 0.221\n",
      "[34,   600] loss: 0.195\n",
      "[34,   630] loss: 0.218\n",
      "[34,   660] loss: 0.215\n",
      "[34,   690] loss: 0.233\n",
      "[34,   720] loss: 0.211\n",
      "[34,   750] loss: 0.193\n",
      "[34,   780] loss: 0.179\n",
      "Accuracy of the network on the 10000 test images: 83 %\n",
      "[35,    30] loss: 0.209\n",
      "[35,    60] loss: 0.199\n",
      "[35,    90] loss: 0.182\n",
      "[35,   120] loss: 0.179\n",
      "[35,   150] loss: 0.180\n",
      "[35,   180] loss: 0.173\n",
      "[35,   210] loss: 0.210\n",
      "[35,   240] loss: 0.188\n",
      "[35,   270] loss: 0.177\n",
      "[35,   300] loss: 0.212\n",
      "[35,   330] loss: 0.187\n",
      "[35,   360] loss: 0.208\n",
      "[35,   390] loss: 0.206\n",
      "[35,   420] loss: 0.203\n",
      "[35,   450] loss: 0.200\n",
      "[35,   480] loss: 0.211\n",
      "[35,   510] loss: 0.198\n",
      "[35,   540] loss: 0.185\n",
      "[35,   570] loss: 0.213\n",
      "[35,   600] loss: 0.199\n",
      "[35,   630] loss: 0.194\n",
      "[35,   660] loss: 0.227\n",
      "[35,   690] loss: 0.210\n",
      "[35,   720] loss: 0.212\n",
      "[35,   750] loss: 0.184\n",
      "[35,   780] loss: 0.198\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[36,    30] loss: 0.180\n",
      "[36,    60] loss: 0.194\n",
      "[36,    90] loss: 0.169\n",
      "[36,   120] loss: 0.156\n",
      "[36,   150] loss: 0.169\n",
      "[36,   180] loss: 0.186\n",
      "[36,   210] loss: 0.200\n",
      "[36,   240] loss: 0.197\n",
      "[36,   270] loss: 0.198\n",
      "[36,   300] loss: 0.219\n",
      "[36,   330] loss: 0.211\n",
      "[36,   360] loss: 0.206\n",
      "[36,   390] loss: 0.209\n",
      "[36,   420] loss: 0.212\n",
      "[36,   450] loss: 0.210\n",
      "[36,   480] loss: 0.201\n",
      "[36,   510] loss: 0.182\n",
      "[36,   540] loss: 0.198\n",
      "[36,   570] loss: 0.196\n",
      "[36,   600] loss: 0.185\n",
      "[36,   630] loss: 0.194\n",
      "[36,   660] loss: 0.216\n",
      "[36,   690] loss: 0.210\n",
      "[36,   720] loss: 0.188\n",
      "[36,   750] loss: 0.202\n",
      "[36,   780] loss: 0.191\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[37,    30] loss: 0.161\n",
      "[37,    60] loss: 0.170\n",
      "[37,    90] loss: 0.174\n",
      "[37,   120] loss: 0.190\n",
      "[37,   150] loss: 0.177\n",
      "[37,   180] loss: 0.210\n",
      "[37,   210] loss: 0.183\n",
      "[37,   240] loss: 0.189\n",
      "[37,   270] loss: 0.171\n",
      "[37,   300] loss: 0.167\n",
      "[37,   330] loss: 0.198\n",
      "[37,   360] loss: 0.187\n",
      "[37,   390] loss: 0.233\n",
      "[37,   420] loss: 0.197\n",
      "[37,   450] loss: 0.206\n",
      "[37,   480] loss: 0.212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37,   510] loss: 0.229\n",
      "[37,   540] loss: 0.234\n",
      "[37,   570] loss: 0.192\n",
      "[37,   600] loss: 0.196\n",
      "[37,   630] loss: 0.215\n",
      "[37,   660] loss: 0.236\n",
      "[37,   690] loss: 0.203\n",
      "[37,   720] loss: 0.193\n",
      "[37,   750] loss: 0.195\n",
      "[37,   780] loss: 0.219\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[38,    30] loss: 0.194\n",
      "[38,    60] loss: 0.172\n",
      "[38,    90] loss: 0.167\n",
      "[38,   120] loss: 0.150\n",
      "[38,   150] loss: 0.175\n",
      "[38,   180] loss: 0.148\n",
      "[38,   210] loss: 0.203\n",
      "[38,   240] loss: 0.179\n",
      "[38,   270] loss: 0.192\n",
      "[38,   300] loss: 0.185\n",
      "[38,   330] loss: 0.199\n",
      "[38,   360] loss: 0.177\n",
      "[38,   390] loss: 0.205\n",
      "[38,   420] loss: 0.192\n",
      "[38,   450] loss: 0.187\n",
      "[38,   480] loss: 0.207\n",
      "[38,   510] loss: 0.188\n",
      "[38,   540] loss: 0.242\n",
      "[38,   570] loss: 0.249\n",
      "[38,   600] loss: 0.215\n",
      "[38,   630] loss: 0.217\n",
      "[38,   660] loss: 0.208\n",
      "[38,   690] loss: 0.203\n",
      "[38,   720] loss: 0.228\n",
      "[38,   750] loss: 0.213\n",
      "[38,   780] loss: 0.201\n",
      "Accuracy of the network on the 10000 test images: 84 %\n",
      "[39,    30] loss: 0.167\n",
      "[39,    60] loss: 0.180\n",
      "[39,    90] loss: 0.173\n",
      "[39,   120] loss: 0.170\n",
      "[39,   150] loss: 0.180\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-3a37738cd3e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# print statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m30\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m29\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# print every 30 mini-batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mvalue_tracker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_plt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 150\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Check Accuracy\n",
    "    acc = acc_check(resnet50, testloader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet50(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
